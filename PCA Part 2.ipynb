{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35685551-a930-405f-a1cd-ce5adb4bdccc",
   "metadata": {},
   "source": [
    "# Answer 1:\n",
    "A projection is a linear transformation that maps data from a high-dimensional space to a lower-dimensional subspace. In PCA, projection is used to reduce the dimensionality of the data by transforming it into a subspace where the variance of the projected data is maximized.\n",
    "\n",
    "# Answer 2:\n",
    "The optimization problem in PCA works by finding the directions of maximum variance in the data set and projecting the data onto these directions. The goal is to identify a set of orthogonal axes, called principal components, that capture the maximum variance in the data while reducing its dimensionality.\n",
    "\n",
    "# Answer 3:\n",
    "The relationship between covariance matrices and PCA is that PCA employs the covariance matrix in order to apply transformations for shrinking the dataset into a set of orthogonal features. The eigenvectors and eigenvalues of the covariance matrix are computed to identify the principal components.\n",
    "\n",
    "# Answer 4:\n",
    "The choice of number of principal components impacts the performance of PCA by determining how much information from the original data is retained in the reduced dataset. The optimal number of principal components is reached when the cumulative variance stops growing fast. A common approach is to choose enough principal components to preserve a certain percentage (e.g., 95%) of the dataâ€™s variance.\n",
    "\n",
    "# Answer 5:\n",
    "PCA can be used in feature selection by performing PCA on the dataset and defining a cut-off of principal components to keep. For each remaining principal component, the loadings are multiplied by the proportion of variance explained and summed across all absolute loadings. Features with small weighted absolute sums of loadings have been least informative to the PCA and can be considered for removal. The benefits of using PCA for feature selection include reduction of noise in the data, filtering out noisy features, and producing independent, uncorrelated features.\n",
    "\n",
    "# Answer 6:\n",
    "Some common applications of PCA in data science and machine learning include visualizing multidimensional data, reducing the number of dimensions in healthcare data, resizing an image, analyzing stock data and forecasting returns in finance, finding patterns in high-dimensional datasets, dimensionality reduction in facial recognition, computer vision, and image compression, and finding patterns in data of high dimension in fields such as data mining, bioinformatics, psychology, etc.\n",
    "\n",
    "# Answer 7:\n",
    "In PCA, spread refers to how spread out the data is along a particular direction or axis while variance measures how much the data varies along that direction or axis. The relationship between spread and variance in PCA is that spread gives us an estimate of variance; more spread means more variance and more information contained.\n",
    "\n",
    "# Answer 8:\n",
    "PCA uses the spread and variance of the data to identify principal components by finding the directions where the data has maximum spread or variance and projecting it onto these directions. The first principal component holds most variance in the data while each subsequent component explains most variance left after its preceding component.\n",
    "\n",
    "# Answer 9:\n",
    "When handling data with high variance in some dimensions but low variance in others, PCA identifies those dimensions with high variance as being more important than those with low variance. These dimensions are captured by the first few principal components while those with low variance may be ignored if enough principal components are not retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ffdb2-a565-4617-8318-0a6428f36f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
