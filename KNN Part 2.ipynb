{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157ecdf2-1d42-4668-bfd6-e4fe9d02fb47",
   "metadata": {},
   "source": [
    "# Answer 1:\n",
    "Euclidean distance and Manhattan distance are two ways of measuring the distance between two points. Euclidean distance is based on squared error distance, whereas Manhattan distance is based on absolute value distance. The choice between using Euclidean or Manhattan distance in KNN depends on the nature of your data and the problem you are trying to solve.\n",
    "\n",
    "# Answer 2:\n",
    "To choose the optimal value of k for a KNN classifier or regressor, you can use techniques such as cross-validation or grid search to test different values of k and select the one that gives the best performance on your dataset.\n",
    "\n",
    "# Answer 3:\n",
    "The choice of distance metric can significantly affect the performance of a KNN classifier or regressor. Different distance metrics may be more appropriate for different types of data or problems, so it's important to choose a distance metric that is well-suited to your specific situation.\n",
    "\n",
    "# Answer 4:\n",
    "Some common hyperparameters in KNN classifiers and regressors include the number of neighbors (k), the distance metric used, and the weighting function used to combine the predictions of the k nearest neighbors. These hyperparameters can affect the performance of the model, and can be tuned using techniques such as cross-validation or grid search to improve model performance.\n",
    "\n",
    "# Answer 5:\n",
    "The size of the training set can affect the performance of a KNN classifier or regressor. A larger training set can improve the robustness of the model, but can also increase the computational cost of making predictions. Techniques such as feature selection or dimensionality reduction can be used to optimize the size of the training set.\n",
    "\n",
    "# Answer 6:\n",
    "Some potential drawbacks of using KNN as a classifier or regressor include its sensitivity to noisy data and irrelevant features, its high computational cost when working with large datasets, and its susceptibility to the curse of dimensionality. These drawbacks can be addressed by carefully preprocessing your data, selecting an appropriate value for k, and using techniques such as feature selection or dimensionality reduction to reduce the dimensionality of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f348152-39e8-40fe-89d3-24e335a966e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
